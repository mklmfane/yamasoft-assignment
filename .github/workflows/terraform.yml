name: Terraform

on:
  workflow_dispatch:
    inputs:
      do_apply:
        description: "Run full terraform apply after bootstrap"
        required: true
        default: "true"
        type: choice
        options: ["true","false"]
      do_destroy:
        description: "Run terraform destroy (manual only)"
        required: true
        default: "true"
        type: choice
        options: ["true","false"]
  push:
    branches: ["main"]
  pull_request:
    branches: ["*"]

permissions:
  id-token: write
  contents: read

env:
  TF_IN_AUTOMATION: "true"
  AWS_REGION: eu-west-1

jobs:
  bootstrap:
    name: Bootstrap (create S3 state, IAM policies, OIDC)
    runs-on: ubuntu-latest
    if: ${{ github.event_name != 'pull_request' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Requires AWS secrets for bootstrap
        env:
          HAS_AKID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          HAS_SAK:  ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${HAS_AKID}" ] || [ -z "${HAS_SAK}" ]; then
            echo "ERROR: Missing repo secrets AWS_ACCESS_KEY_ID and/or AWS_SECRET_ACCESS_KEY." >&2
            exit 1
          fi

      - name: Configure AWS credentials (bootstrap via access keys)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}

      - name: Verify caller identity
        run: aws sts get-caller-identity

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.3
          terraform_wrapper: false

      # -------- CHANGED: temporarily remove s3 backend from the tree --------
      - name: Temporarily disable S3 backend files
        run: |
          set -euo pipefail
          mkdir -p .ci-backend-stash

          # find backend "s3" in TF files (skip the stash dir itself)
          mapfile -t files < <(grep -Rl --include='*.tf' --include='*.tf.json' 'backend *"s3"' . | grep -v '^./\.ci-backend-stash/' || true)

          if [ ${#files[@]} -eq 0 ]; then
                echo "No backend \"s3\" blocks found to stash."
                exit 0
          fi

          # record original paths
          printf '%s\n' "${files[@]}" > .ci-backend-stash/manifest.txt

          i=0
          for f in "${files[@]}"; do
                echo "Stashing $f"
                cp "$f" ".ci-backend-stash/file_${i}"
                rm "$f"
                i=$((i+1))
          done  

      - name: Discover existing IAM policy ARNs (avoid duplicate creates)
        shell: bash
        run: |
          set -euo pipefail

          # Look up customer-managed policies by name
          B_ACK=$(aws iam list-policies --scope Local \
                   --query "Policies[?PolicyName=='tf-backend-rw'].Arn | [0]" \
                   --output text 2>/dev/null || echo "None")
          VPC_APPLY=$(aws iam list-policies --scope Local \
                   --query "Policies[?PolicyName=='tf-vpc-apply'].Arn | [0]" \
                   --output text 2>/dev/null || echo "None")

          # Normalize "None" / "null" / empty to blank
          norm() {
            local v="$1"
            if [ "$v" = "None" ] || [ "$v" = "null" ] || [ -z "$v" ]; then
              echo ""
            else
              echo "$v"
            fi
          }

          B_ACK="$(norm "$B_ACK")"
          VPC_APPLY="$(norm "$VPC_APPLY")"

          # Export for terraform as input variables
          echo "TF_VAR_existing_backend_rw_policy_arn=$B_ACK"     >> "$GITHUB_ENV"
          echo "TF_VAR_existing_vpc_apply_policy_arn=$VPC_APPLY"  >> "$GITHUB_ENV"

          echo "Detected backend-rw: ${B_ACK:-<none>}"
          echo "Detected vpc-apply : ${VPC_APPLY:-<none>}"
 

      - name: Terraform init (local backend via fallback)
        run: terraform init -reconfigure -input=false

      - name: Import existing IAM policy ARNs in case they exists
        shell: bash
        run: |
          set -euo pipefail
          set -e
          B_ARN="$(aws iam list-policies --scope Local --query "Policies[?PolicyName=='tf-backend-rw'].Arn | [0]" --output text || echo '')"
          if [ -n "$B_ARN" ]; then
            terraform state show module.iam-tf-policies.aws_iam_policy.tf_backend_rw[0] >/dev/null 2>&1 || \
            terraform import module.iam-tf-policies.aws_iam_policy.tf_backend_rw[0] "$B_ARN"
          fi

          V_ARN="$(aws iam list-policies --scope Local --query "Policies[?PolicyName=='tf-vpc-apply'].Arn | [0]" --output text || echo '')"
          if [ -n "$V_ARN" ]; then
            terraform state show module.iam-tf-policies.aws_iam_policy.tf_vpc_apply[0] >/dev/null 2>&1 || \
            terraform import module.iam-tf-policies.aws_iam_policy.tf_vpc_apply[0] "$V_ARN"
          fi

      - name: Bootstrap apply (bucket + policies + OIDC role)
        run: |
          set -euo pipefail
          terraform apply \
            -input=false \
            -auto-approve \
            -target=module.s3-bucket-state-oidc \
            -target=module.iam-tf-policies \
            -target=module.github-oidc

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Export bootstrap outputs
        id: out
        run: |
          set -euo pipefail
          tfjson=$(terraform output -json || echo '{}')

          BUCKET=$(echo "$tfjson" | jq -r '.s3_bucket_id.value // empty')
          KEY=$(echo "$tfjson" | jq -r '.backend_key.value // empty')
          USE_LOCKFILE=$(echo "$tfjson" | jq -r '.use_lockfile.value // "true"')
          ROLE_ARN=$(echo "$tfjson" | jq -r '.github_oidc_role_arn.value // empty')

          echo "bucket=$BUCKET"             >> $GITHUB_OUTPUT
          echo "key=$KEY"                   >> $GITHUB_OUTPUT
          echo "use_lockfile=$USE_LOCKFILE" >> $GITHUB_OUTPUT
          echo "role_arn=$ROLE_ARN"         >> $GITHUB_OUTPUT

      # -------- CHANGED: restore the original backend file(s) ----------
      - name: Restore S3 backend files
        run: |
          set -euo pipefail
          if [ ! -f .ci-backend-stash/manifest.txt ]; then
            echo "Nothing to restore."
            exit 0
          fi

          i=0
          while IFS= read -r dest; do
            echo "Restoring to $dest"
            mkdir -p "$(dirname "$dest")"
            mv ".ci-backend-stash/file_${i}" "$dest"
            i=$((i+1))
          done < .ci-backend-stash/manifest.txt

          rm -rf .ci-backend-stash  

    outputs:
      bucket:       ${{ steps.out.outputs.bucket }}
      key:          ${{ steps.out.outputs.key }}
      use_lockfile: ${{ steps.out.outputs.use_lockfile }}
      role_arn:     ${{ steps.out.outputs.role_arn }}

  deploy:
    name: Migrate backend âžœ Plan/Apply (OIDC)
    runs-on: ubuntu-latest
    needs: bootstrap
    if: ${{ needs.bootstrap.result == 'success' && needs.bootstrap.outputs.role_arn != '' }}

    env:
      TF_BACKEND_BUCKET:       ${{ needs.bootstrap.outputs.bucket }}
      TF_BACKEND_KEY:          ${{ needs.bootstrap.outputs.key }}
      TF_BACKEND_USE_LOCKFILE: ${{ needs.bootstrap.outputs.use_lockfile }}
      AWS_OIDC_ROLE_ARN:       ${{ needs.bootstrap.outputs.role_arn }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.AWS_OIDC_ROLE_ARN }}
          role-session-name: gha-terraform

      - name: Verify caller identity (OIDC)
        run: aws sts get-caller-identity

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.3
          terraform_wrapper: false

      - name: Cache .terraform providers
        uses: actions/cache@v4
        with:
          path: |
            **/.terraform
            ~/.terraform.d/plugin-cache
          key: ${{ runner.os }}-tf-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-tf-

      - name: Terraform fmt
        run: terraform fmt -recursive -diff || true

      - name: Init S3 backend + migrate state (no prompts)
        run: |
          terraform init \
            -migrate-state \
            -input=false \
            -backend-config="bucket=${TF_BACKEND_BUCKET}" \
            -backend-config="key=${TF_BACKEND_KEY}" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="use_lockfile=${TF_BACKEND_USE_LOCKFILE}"

      - name: Terraform validate
        run: terraform validate -no-color

      - name: Terraform plan (PR)
        if: github.event_name == 'pull_request'
        run: terraform plan -input=false -no-color -out=tfplan.bin

      - name: Upload plan (PR)
        if: github.event_name == 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: tfplan.bin
          retention-days: 3

      - name: Terraform plan (apply path)
        if: github.event_name != 'pull_request'
        run: terraform plan -input=false -no-color

      - name: Terraform apply
        if: github.event_name != 'pull_request' && (github.event_name != 'workflow_dispatch' || inputs.do_apply == 'true')
        run: terraform apply -input=false -auto-approve

      - name: Terraform destroy (manual only)
        if: github.event_name == 'workflow_dispatch' && inputs.do_destroy == 'true'
        run: terraform destroy -input=false -auto-approve
